{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV5JU9v-b0cj"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahmouddraz/xai/blob/main/notebooks/homework/grad_cam/GradCAM_Exercise.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEBJk3y5fRfP"
      },
      "source": [
        "# Review \n",
        "**CAM**: uses the weights from the golabe average pooling layer to weight the activation of the last convoutional layer. cam_values = np.dot(weights, conv_values)\n",
        "\n",
        "**Saliency** uses calculates the gradinets of the loss and overlay it on the orginal image \n",
        "saleincy = grad(loss, conv_values)\n",
        "\n",
        "**GradCAM** uses the gradient to wieght the activations of the last convultional layer (it combines CAM and Salieny). The benfits is: more accurate allocation of the  \n",
        "\n",
        "grad_cam = np.dot(grad(loss, conv), conv_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMFxuBIxg8od"
      },
      "source": [
        "# GradCAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQg5ANOBv4mz"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRZkfcUib15V"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow_datasets as tfds \n",
        "import tensorflow_hub as hub \n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as k \n",
        "\n",
        "import cv2 \n",
        "import numpy as np \n",
        "import seaborn as sn \n",
        "import pandas as pd \n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd0JITkUk1cV"
      },
      "source": [
        "## Load dataset (CATS_VS_DOGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbtJ9uWuiieq"
      },
      "outputs": [],
      "source": [
        "# chnage the source of the datasets, the one in new version of tensorflow is not wokring\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL', 'https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrU8GOrtiJF1"
      },
      "outputs": [],
      "source": [
        "# do not show the prcess and progress bar while loading\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n",
        "\n",
        "# load the dataset given the splits defined above\n",
        "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split=splits)\n",
        "\n",
        "(train_examples, validation_examples, test_examples) = dataset\n",
        "\n",
        "num_examples = info.splits['train'].num_examples\n",
        "num_classes = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JM2tiiijo4d"
      },
      "outputs": [],
      "source": [
        "# resizes the image and normalizes the pixel values\n",
        "def normalize(image, label):\n",
        "  image = tf.image.resize(image, (224, 224)) / 255.0\n",
        "  return  image, label\n",
        "\n",
        "# prepare batches\n",
        "train_batches = train_examples.shuffle(num_examples // 4).map(normalize).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "validation_batches = validation_examples.map(normalize).batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "# for testing, we make a batch size of 1 image every batch\n",
        "test_batches = test_examples.map(normalize).batch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWcf-07Tk5MQ"
      },
      "source": [
        "## Import model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cIsQNDGsQaP"
      },
      "outputs": [],
      "source": [
        "# load a pretrained model if the training is taking very long time \n",
        "model = keras.models.load_model('/content/drive/MyDrive/XAI workshop/Models/cnn_grad_cam.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xh-trXFxqnJ"
      },
      "source": [
        "###  Activation Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4aLW7j9w9Ue"
      },
      "outputs": [],
      "source": [
        "# detrmine the layers you would like to track their activation\n",
        "############################### CODE HERE ###############################\n",
        "\n",
        "# create a another model from the original that returns the activation sof these 18  layers\n",
        "\n",
        "############################### CODE HERE ###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBL7HpXOx8Cq"
      },
      "source": [
        "### Gradients model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTU9vgEFyXkn"
      },
      "outputs": [],
      "source": [
        "#get the layer names\n",
        "layer_names = []\n",
        "for layer in outputs: \n",
        "    layer_names.append(layer.name.split('/')[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nMgqjjfxpvw"
      },
      "outputs": [],
      "source": [
        "# This model adjust the output to return the gradients in a certain layer giving its name\n",
        "\n",
        "############################### CODE HERE ###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI5aWoLzydX_"
      },
      "source": [
        "### Prepare a testing image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sno1zk3dyczN"
      },
      "outputs": [],
      "source": [
        "# select a random image for the testing dataset\n",
        "for img, label in test_batches.shuffle(1000).take(1): \n",
        "  sample_image = img[0]\n",
        "  sample_label = label[0]\n",
        "\n",
        "# expand its dimentions to match the input shape of the model that will predict its label, get its activation and calculate the gradients\n",
        "sample_image_processed = np.expand_dims(sample_image, axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQlqDdyjz02G"
      },
      "source": [
        "### Get the prediction of the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW7y_I9ezygp",
        "outputId": "c2b239f8-d391-4b21-fc05-86fe3fad8c47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# by applyging the argmax function on the output of the original model\n",
        "pred_label = np.argmax(model.predict(sample_image_processed), axis=-1)[0]\n",
        "pred_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9u76TwJzLCA"
      },
      "source": [
        "### Get the activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCLA9YAZzUg9"
      },
      "outputs": [],
      "source": [
        "# call the activations model to get the activation tensors in al 16 layers \n",
        "\n",
        "############################### CODE HERE ###############################\n",
        "\n",
        "# stadrize the vlaue by taking the mean and divding by stadard divation\n",
        "sample_activation = activations[0][0,:,:,16]\n",
        "sample_activation-=sample_activation.mean()\n",
        "sample_activation/=sample_activation.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6f7pLk07yV"
      },
      "source": [
        "### Calculate the loss and the gradients of the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebO5KV12069E"
      },
      "outputs": [],
      "source": [
        "with tf.GradientTape() as tap:\n",
        "\n",
        "    #apply the the grad model to the the image you want to explain \n",
        "    ############################### CODE HERE ###############################\n",
        "    \n",
        "    # asks GradnientTap to recod the values of the conv layer  (you need it for the head map)\n",
        "    ############################### CODE HERE ###############################\n",
        "\n",
        "    #get the predicted label from the prediction results \n",
        "    ############################### CODE HERE ###############################\n",
        "\n",
        "    # convert the the ture label to float32 \n",
        "    ############################### CODE HERE ###############################\n",
        "\n",
        "    # # You want to calcuata the gradient of the loss over the layer values\n",
        "    # # loss = accual_label * log(pred_label)\n",
        "    # # recall: cross entropy is measures the diffrence between the probability of two random varaibles. \n",
        "    # # in our case the these variabels are the accual_label and the pred_label. \n",
        "    \n",
        "    # # claculate the losss : Cross  entropy \n",
        "    loss =  -1 * (actual_label * tf.math.log(pred_label + 0.00001) + (1 - actual_label) * tf.math.log(1- pred_label + 0.00001))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obpp2Mes1HH3"
      },
      "outputs": [],
      "source": [
        "# calcualte the gradient of of the loss (None, 224, 224, 512)\n",
        "############################### CODE HERE ###############################\n",
        "\n",
        "# Take the mean of all feature frams, shape([512])\n",
        "############################### CODE HERE ###############################\n",
        "\n",
        "# squeeze the tensor, outshape an tensor with (512)\n",
        "############################### CODE HERE ###############################\n",
        "\n",
        "# take out the the numpy array \n",
        "############################### CODE HERE ###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZHnwlkL2C9K"
      },
      "source": [
        "### The fun part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Y_CpTzdB5ynL",
        "outputId": "92edcd5e-3286-4a10-ef69-1a4e01279837"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.21.6'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "3Qbalos62dx5",
        "outputId": "1c183640-91ca-4639-d301-3d761b59e5a0"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a771031a242a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### that is why it is callsed GRAD-weighted ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mconv_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mgrad_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: output array is read-only"
          ]
        }
      ],
      "source": [
        "#weight the each feature map in the activations (224, 224, 512) or the output values of the conv layer by the gradients (512)\n",
        "\n",
        "# We weight all feature map in in the last layer by  by the grad \n",
        "### that is why it is callsed GRAD-weighted ## \n",
        "############################### CODE HERE ###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5GJDEFZ3rwQ"
      },
      "source": [
        "### Calculate the heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZBN1NlU3nqn"
      },
      "outputs": [],
      "source": [
        "############################### CODE HERE ###############################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZyE9qHm33R7"
      },
      "source": [
        "### Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7oDOyAv3-ZH"
      },
      "outputs": [],
      "source": [
        "f,ax = plt.subplots(2,2, figsize=(15,8))\n",
        "\n",
        "ax[0,0].imshow(sample_image)\n",
        "ax[0,0].set_title(f\"True label: {sample_label} \\n Predicted label: {pred_label}\")\n",
        "ax[0,0].axis('off')\n",
        "\n",
        "ax[0,1].imshow(sample_activation)\n",
        "ax[0,1].set_title(\"Random feature map\")\n",
        "ax[0,1].axis('off')\n",
        "\n",
        "ax[1,0].imshow(heatmap)\n",
        "ax[1,0].set_title(\"Class Activation Map\")\n",
        "ax[1,0].axis('off')\n",
        "\n",
        "ax[1,1].imshow(super_imposed_image)\n",
        "ax[1,1].set_title(\"Activation map superimposed\")\n",
        "ax[1,1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_Tv7dvl8Fhi"
      },
      "source": [
        "### Task\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlLKWaWs8O_Z"
      },
      "source": [
        "- Select the output of other conv layers and compare the graphs\n",
        "- Track the shape changes of the activations, gradients and image throughout the process and justify the changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Ykydlw-8Ofi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbFtUqJT4BXp"
      },
      "source": [
        "## In case you do nto have a pretrained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7lA9EW4QRl"
      },
      "source": [
        "#### Run this part of the note book afete loading the datasets if you do not have a pretrain mdoel. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufr-wWXyk6sV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import vgg16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-AP15ovlBnb"
      },
      "outputs": [],
      "source": [
        "base_model = vgg16.VGG16(input_shape=input_shape, weights='imagenet', include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKN5iihLmsfz"
      },
      "outputs": [],
      "source": [
        "output = keras.layers.GlobalAveragePooling2D()(base_model.output) \n",
        "output = keras.layers.Dense(2, activation='softmax', )(output) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaWFi9eSnfA1"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# change the model the make the output you want to visualize \n",
        "visaulization_model = Model(inputs=model.input, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhvzXGqHnuEb"
      },
      "outputs": [],
      "source": [
        "for layer in base_model.layers[:-4]:\n",
        "   layer.trainable=False "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xH6B9d2oMRD"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3aeFtnzpqev"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.eager.monitoring import Metric\n",
        "model.compile(\n",
        "    optimizer=optimizer, \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics='accuracy'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QPO7YwPqAXS"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GradCAM_Exercise.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
