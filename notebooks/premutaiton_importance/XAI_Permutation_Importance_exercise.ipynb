{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aS3QoxBb_Uo"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahmouddraz/xai/blob/main/notebooks/premutaiton_importance/XAI_Permutation%20Importance_exercise.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN4vS0KPRuPR"
      },
      "source": [
        "# Permutation Importance\n",
        "\n",
        "## 1. Basic Idea\n",
        "\n",
        "The main idea behind permutation importance is to shuffle the value of one feature column and then check the performance of a pretrained network on this permuted dataset. The performance will probably decrease, but the relative drop will indicate how important the feature is. \n",
        "\n",
        "Hence, this method is model agnostic.\n",
        "\n",
        "Further information can be found on https://arxiv.org/pdf/1801.01489.pdf \n",
        "\n",
        "## 2. Algorithm\n",
        "\n",
        "1. Take a model that was fit to the training set\n",
        "2. Estimate the predicted performance of the model on a validation dataset and take that as the baseline performance\n",
        "3. For each feature j:\n",
        "  \n",
        "  a. Shuffle all the values of the column in the original dataset (the other columns and labels are fixed)\n",
        "\n",
        "  b. Record the performance of the shuffeled dataset on the original network \n",
        "\n",
        "  c. Compute the feature importance as the absolute difference between the baseline performance and the performance of the shuffeled dataset.\n",
        "\n",
        "Repeat a - c for a large number of times and average over all trials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS5dvRMBgXwG"
      },
      "source": [
        "## 3. Permutation Importance applied to a stroke dataset using a Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MF6kCAI2VetR"
      },
      "outputs": [],
      "source": [
        "#need newer matplotlib version for nice bar plots\n",
        "#!pip install matplotlib==3.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9VbuFkCRtaF"
      },
      "outputs": [],
      "source": [
        "! git clone https://gist.github.com/aishwarya8615/d2107f828d3f904839cbcb7eaa85bd04 'stroke'\n",
        "! git clone https://github.com/mahmouddraz/xai 'xai_workshop'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J0xoMA9g9LW"
      },
      "source": [
        "Preparing the dataset to feed it into a Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xc1uMRD6EcT"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import sys \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tabulate import tabulate\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNyUlj2G4Gev"
      },
      "outputs": [],
      "source": [
        "#Read data\n",
        "data = pd.read_csv('/content/stroke/healthcare-dataset-stroke-data.csv')\n",
        "\n",
        "#Print the data\n",
        "print(f'We have {len(data)} datapoints. The first ten data points are:')\n",
        "print(data.iloc[0:10,:].to_markdown()) \n",
        "\n",
        "# Load pretrained model and data\n",
        "with open('/content/xai_workshop/pretrained_models/rf_stroke/rf_stroke.pickle', \"rb\") as f:\n",
        "  rf = pickle.load(f)\n",
        "with open('/content/xai_workshop/pretrained_models/rf_stroke/rf_stroke_X_train.pickle', \"rb\") as f:\n",
        "  X_train = pickle.load(f)\n",
        "with open('/content/xai_workshop/pretrained_models/rf_stroke/rf_stroke_X_test.pickle', \"rb\") as f:\n",
        "  X_test = pickle.load(f)\n",
        "with open('/content/xai_workshop/pretrained_models/rf_stroke/rf_stroke_y_test.pickle', \"rb\") as f:\n",
        "  y_test = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsEZhJd2g2Po"
      },
      "source": [
        "Create the Random Forest classifier and train it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RN2rTi5grGv"
      },
      "outputs": [],
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(f\"The classifier is trained has an accuracy of {accuracy_score(y_test, y_pred)}.\")\n",
        "baseline_performance = accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fpasfo_hSrb"
      },
      "source": [
        "Now we apply permutation importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYCn2-L-gtwx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "runs_per_feature = 50\n",
        "\n",
        "feature_and_importance = {}\n",
        "\n",
        "# Iterate over all features\n",
        "for fx, feature in enumerate(X_test): \n",
        "\n",
        "  ################## IMPLEMENTATION OF PERMUTATION IMPORTANCE ##################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGpBkSs9uLnd"
      },
      "source": [
        "Finally we may want to plot the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POBz-kLuhepx"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=[12, 8])\n",
        "bars = ax.barh(np.arange(len(feature_and_importance)), feature_and_importance.values())\n",
        "\n",
        "ax.bar_label(bars, labels=feature_and_importance.keys())\n",
        "ax.set_yticklabels([])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW0IvbB9uaa0"
      },
      "source": [
        "## 4. Exercises\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "1. What happens if we increase the number of `runs_per_feature`? What happens if we decrease it? Explain your reasoning.\n",
        "2. What changes if we just set one feature to zero instead of shuffeling the values?\n",
        "3. What happens if we use the same method for a neural network? Please check the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiOWHzZJMogL"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzlFMvN2UasV"
      },
      "outputs": [],
      "source": [
        "with open('/content/xai_workshop/pretrained_models/nn_stroke/nn_stroke_X_train.pickle', \"rb\") as f:\n",
        "  X_train = pickle.load(f)\n",
        "with open('/content/xai_workshop/pretrained_models/nn_stroke/nn_stroke_X_test.pickle', \"rb\") as f:\n",
        "  X_test = pickle.load(f)\n",
        "with open('/content/xai_workshop/pretrained_models/nn_stroke/nn_stroke_y_test.pickle', \"rb\") as f:\n",
        "  y_test = pickle.load(f)\n",
        "\n",
        "nn = keras.models.load_model('/content/xai_workshop/pretrained_models/nn_stroke/nn_stroke')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCuKMz_ez51-"
      },
      "outputs": [],
      "source": [
        "#Compute the baseline performance\n",
        "y_pred = nn.predict(X_test)\n",
        "\n",
        "print(f\"The classifier is trained has an accuracy of {accuracy_score(y_test, np.round(abs(y_pred)), normalize=True) }.\")\n",
        "baseline_performance = accuracy_score(y_test, np.round(abs(y_pred)), normalize=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYNT72Yv3tv0"
      },
      "source": [
        "Again we implement permutation importance for the trained network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pps8iOBH327W"
      },
      "outputs": [],
      "source": [
        "runs_per_feature = 50\n",
        "\n",
        "################## IMPLEMENTATION OF PERMUTATION IMPORTANCE ##################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBq0F6OP4NeD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(figsize=[12, 8])\n",
        "bars = ax.barh(np.arange(len(feature_and_importance)), feature_and_importance.values())\n",
        "\n",
        "ax.bar_label(bars, labels=feature_and_importance.keys())\n",
        "ax.set_yticklabels([])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "XAI_Permutation Importance_exercise.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
